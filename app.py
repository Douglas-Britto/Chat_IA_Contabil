import streamlit as st
import os
import pandas as pd
import pdfplumber
from PIL import Image
from openai import OpenAI

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Auditor Fiscal IA", layout="wide")

# Conex√£o com OpenAI via segredo do Streamlit
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Interface
st.title("üß† Auditor Fiscal IA")
st.write("Este painel l√™ documentos e responde perguntas com intelig√™ncia artificial.")

# Campo de pergunta
pergunta = st.text_input("Digite sua pergunta:", placeholder="Ex: grafico_carga_tributaria.png")
if "historico" not in st.session_state:
    st.session_state.historico = []

# Fun√ß√£o para ler arquivos da raiz do projeto
def ler_arquivos(pasta="."):
    caminho = os.path.join(os.path.dirname(__file__), pasta)
    textos = []
    if not os.path.exists(caminho):
        st.error("üìÅ Nenhum diret√≥rio encontrado.")
        return ""
    for arquivo in os.listdir(caminho):
        caminho_arquivo = os.path.join(caminho, arquivo)
        try:
            if arquivo.endswith(".txt"):
                with open(caminho_arquivo, "r", encoding="utf-8") as f:
                    textos.append(f.read())
            elif arquivo.endswith(".csv"):
                df = pd.read_csv(caminho_arquivo)
                textos.append(df.to_string())
            elif arquivo.endswith(".pdf"):
                with pdfplumber.open(caminho_arquivo) as pdf:
                    texto_pdf = "\n".join(page.extract_text() for page in pdf.pages if page.extract_text())
                    textos.append(texto_pdf)
        except Exception as e:
            st.warning(f"Erro ao ler '{arquivo}': {e}")
    return "\n".join(textos)

# Fun√ß√£o para gerar resposta com IA
def responder_ia(pergunta, documentos):
    prompt = f"""
Voc√™ √© um auditor fiscal inteligente. Analise os documentos abaixo e responda √† pergunta com clareza e l√≥gica.

Documentos:
{documentos}

Pergunta: {pergunta}
"""
    resposta = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Voc√™ √© um auditor fiscal que gera an√°lises claras e objetivas."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=700
    )
    return resposta.choices[0].message.content

# Fun√ß√£o para exibir apenas o gr√°fico solicitado
def mostrar_grafico_solicitado(pergunta, pasta="."):
    nome_grafico = pergunta.strip().lower()
    caminho = os.path.join(os.path.dirname(__file__), pasta)
    for arquivo in os.listdir(caminho):
        if arquivo.lower().endswith(".png") and nome_grafico in arquivo.lower():
            caminho_arquivo = os.path.join(caminho, arquivo)
            try:
                st.markdown("---")
                st.markdown("### üìä Gr√°fico solicitado")
                st.image(caminho_arquivo, caption=arquivo, use_container_width=True)
                return
            except Exception as e:
                st.warning(f"Erro ao exibir '{arquivo}': {e}")
                return
    # Se nenhum gr√°fico for encontrado
    st.info("üìÅ Nenhum gr√°fico correspondente foi encontrado.")

# Execu√ß√£o principal
if pergunta:
    documentos = ler_arquivos()
    if documentos:
        resposta = responder_ia(pergunta, documentos)
        st.markdown("### üìÑ Resposta da IA")
        st.markdown(resposta)
        st.session_state.historico.append((pergunta, resposta))
        mostrar_grafico_solicitado(pergunta)
    else:
        st.warning("‚ö†Ô∏è Nenhum conte√∫do foi encontrado no diret√≥rio do projeto.")

# Hist√≥rico de perguntas
if st.session_state.historico:
    st.markdown("---")
    st.markdown("### üóÇ Hist√≥rico de perguntas")
    for i, (q, r) in enumerate(reversed(st.session_state.historico), 1):
        st.markdown(f"**{i}. {q}**")
        st.markdown(f"{r}")
